








  0%|          | 10/2080 [00:18<1:03:11,  1.83s/it]









  1%|          | 20/2080 [00:35<1:00:28,  1.76s/it]








  1%|▏         | 29/2080 [00:52<1:01:48,  1.81s/it]








  2%|▏         | 39/2080 [01:10<1:01:23,  1.80s/it]









  2%|▏         | 49/2080 [01:28<59:06,  1.75s/it]
  2%|▏         | 50/2080 [01:29<59:18,  1.75s/it][INFO|trainer.py:3376] 2024-02-29 02:59:59,196 >> ***** Running Evaluation *****
[INFO|trainer.py:3378] 2024-02-29 02:59:59,196 >>   Num examples = 439
[INFO|trainer.py:3381] 2024-02-29 02:59:59,196 >>   Batch size = 8
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 14, in <module>
    main()
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 5, in main
    run_exp()
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/tuner.py", line 33, in run_exp
    run_rm(model_args, data_args, training_args, finetuning_args, callbacks)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/workflow.py", line 55, in run_rm
    train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 1624, in train
    return inner_training_loop(
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 2029, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 2412, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 3229, in evaluate
    output = eval_loop(
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 3418, in evaluation_loop
    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 3635, in prediction_step
    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/trainer.py", line 40, in compute_loss
    _, _, values = model(**inputs, output_hidden_states=True, return_dict=True)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 817, in forward
    return model_forward(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 805, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/trl/models/modeling_value_head.py", line 187, in forward
    lm_logits = lm_logits.float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB (GPU 0; 31.75 GiB total capacity; 20.41 GiB already allocated; 4.67 GiB free; 26.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 14, in <module>
    main()
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 5, in main
    run_exp()
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/tuner.py", line 33, in run_exp
    run_rm(model_args, data_args, training_args, finetuning_args, callbacks)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/workflow.py", line 55, in run_rm
    train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 1624, in train
    return inner_training_loop(
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 2029, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 2412, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 3229, in evaluate
    output = eval_loop(
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 3418, in evaluation_loop
    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 3635, in prediction_step
    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/trainer.py", line 40, in compute_loss
    _, _, values = model(**inputs, output_hidden_states=True, return_dict=True)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 817, in forward
    return model_forward(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 805, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/trl/models/modeling_value_head.py", line 187, in forward
    lm_logits = lm_logits.float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB (GPU 0; 31.75 GiB total capacity; 20.41 GiB already allocated; 4.67 GiB free; 26.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF