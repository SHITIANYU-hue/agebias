







  0%|          | 7/2080 [00:29<2:08:25,  3.72s/it]Traceback (most recent call last):
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 14, in <module>
    main()
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 5, in main
    run_exp()
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/tuner.py", line 33, in run_exp
    run_rm(model_args, data_args, training_args, finetuning_args, callbacks)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/workflow.py", line 55, in run_rm
    train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 1624, in train
    return inner_training_loop(
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 2902, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/trainer.py", line 40, in compute_loss
    _, _, values = model(**inputs, output_hidden_states=True, return_dict=True)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 817, in forward
    return model_forward(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 805, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/trl/models/modeling_value_head.py", line 187, in forward
    lm_logits = lm_logits.float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 706.00 MiB (GPU 0; 31.75 GiB total capacity; 13.99 GiB already allocated; 357.69 MiB free; 14.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 14, in <module>
    main()
  File "/home/student2021/srcao/llama-factory/src/train_bash.py", line 5, in main
    run_exp()
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/tuner.py", line 33, in run_exp
    run_rm(model_args, data_args, training_args, finetuning_args, callbacks)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/workflow.py", line 55, in run_rm
    train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 1624, in train
    return inner_training_loop(
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/transformers/trainer.py", line 2902, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/student2021/srcao/llama-factory/src/llmtuner/train/rm/trainer.py", line 40, in compute_loss
    _, _, values = model(**inputs, output_hidden_states=True, return_dict=True)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 817, in forward
    return model_forward(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/accelerate/utils/operations.py", line 805, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/student2021/anaconda3/envs/llama-factory/lib/python3.10/site-packages/trl/models/modeling_value_head.py", line 187, in forward
    lm_logits = lm_logits.float()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 706.00 MiB (GPU 0; 31.75 GiB total capacity; 13.99 GiB already allocated; 357.69 MiB free; 14.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF